{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten, \n",
    "    Conv2D,\n",
    "    MaxPooling2D)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.', 'Peter', 'Blackburn', 'BRUSSELS', '1996-08-22', 'The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 'shun', 'British', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.', 'Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.', '\"', 'We', 'do', \"n't\", 'support', 'any', 'such', 'recommendation', 'because', 'we', 'do', \"n't\", 'see', 'any', 'grounds', 'for', 'it', ',', '\"', 'the', 'Commission', \"'s\", 'chief', 'spokesman', 'Nikolaus', 'van', 'der', 'Pas', 'told', 'a', 'news', 'briefing', '.', 'He', 'said', 'further', 'scientific', 'study', 'was', 'required', 'and', 'if', 'it', 'was', 'found', 'that', 'action', 'was', 'needed', 'it', 'should', 'be', 'taken', 'by', 'the', 'European', 'Union', '.', 'He', 'said', 'a', 'proposal', 'last', 'month', 'by', 'EU', 'Farm', 'Commissioner', 'Franz', 'Fischler', 'to', 'ban', 'sheep', 'brains', ',', 'spleens', 'and', 'spinal', 'cords', 'from', 'the', 'human', 'and', 'animal', 'food', 'chains', 'was', 'a', 'highly', 'specific', 'and', 'precautionary', 'move', 'to', 'protect', 'human', 'health', '.', 'Fischler', 'proposed', 'EU-wide', 'measures', 'after', 'reports', 'from', 'Britain', 'and', 'France', 'that', 'under', 'laboratory', 'conditions', 'sheep', 'could', 'contract', 'Bovine', 'Spongiform', 'Encephalopathy', '(', 'BSE', ')', '--', 'mad', 'cow', 'disease', '.', 'But', 'Fischler', 'agreed', 'to', 'review', 'his', 'proposal', 'after', 'the', 'EU', \"'s\", 'standing', 'veterinary', 'committee', ',', 'mational', 'animal', 'health', 'officials', ',', 'questioned', 'if', 'such', 'action', 'was', 'justified', 'as', 'there', 'was', 'only', 'a', 'slight', 'risk', 'to', 'human', 'health', '.', 'Spanish', 'Farm', 'Minister', 'Loyola', 'de', 'Palacio', 'had', 'earlier', 'accused', 'Fischler', 'at', 'an', 'EU', 'farm', 'ministers', \"'\", 'meeting', 'of', 'causing', 'unjustified', 'alarm', 'through', '\"', 'dangerous', 'generalisation', '.', '\"', '.', 'Only', 'France', 'and', 'Britain', 'backed', 'Fischler', \"'s\", 'proposal', '.', 'The', 'EU', \"'s\", 'scientific', 'veterinary', 'and', 'multidisciplinary', 'committees', 'are', 'due', 'to', 're-examine', 'the', 'issue', 'early', 'next', 'month', 'and', 'make', 'recommendations', 'to', 'the', 'senior', 'veterinary', 'officials', '.', 'Sheep', 'have', 'long', 'been', 'known', 'to', 'contract', 'scrapie', ',', 'a', 'brain-wasting', 'disease', 'similar', 'to', 'BSE', 'which', 'is', 'believed', 'to', 'have', 'been', 'transferred', 'to', 'cattle', 'through', 'feed', 'containing', 'animal', 'waste', '.', 'British', 'farmers', 'denied', 'on', 'Thursday', 'there', 'was', 'any', 'danger', 'to', 'human', 'health', 'from', 'their', 'sheep', ',', 'but', 'expressed', 'concern', 'that', 'German', 'government', 'advice', 'to', 'consumers', 'to', 'avoid', 'British', 'lamb', 'might', 'influence', 'consumers', 'across', 'Europe', '.', '\"', 'What', 'we', 'have', 'to', 'be', 'extremely', 'careful', 'of', 'is', 'how', 'other', 'countries', 'are', 'going', 'to', 'take', 'Germany', \"'s\", 'lead', ',', '\"', 'Welsh', 'National', 'Farmers', \"'\", 'Union', '(', 'NFU', ')', 'chairman', 'John', 'Lloyd', 'Jones', 'said', 'on', 'BBC', 'radio', '.', 'Bonn', 'has', 'led', 'efforts', 'to', 'protect', 'public', 'health', 'after', 'consumer', 'confidence', 'collapsed', 'in', 'March', 'after', 'a', 'British', 'report', 'suggested', 'humans', 'could', 'contract', 'an', 'illness', 'similar', 'to', 'mad', 'cow', 'disease', 'by', 'eating', 'contaminated', 'beef', '.', 'Germany', 'imported', '47,600', 'sheep', 'from', 'Britain', 'last', 'year', ',', 'nearly', 'half', 'of', 'total', 'imports', '.', 'It', 'brought', 'in', '4,275', 'tonnes', 'of', 'British', 'mutton', ',', 'some', '10', 'percent', 'of', 'overall', 'imports', '.', '-DOCSTART-', 'Rare', 'Hendrix', 'song', 'draft', 'sells', 'for', 'almost', '$', '17,000']\n",
      "ha ['to', 'Br', '.', \"'s\", 'th', 'wa', '\"', ',', 'a', 'an']\n",
      "ha ['to', 'Bri', '.', \"'s\", 'the', 'was', '\"', ',', 'a', 'and']\n",
      "ho ['to', 'sh', '.', \"'s\", 'he', 'as', '\"', ',', 'a', 'nd']\n",
      "ho ['to', 'ish', '.', \"'s\", 'the', 'was', '\"', ',', 'a', 'and']\n"
     ]
    }
   ],
   "source": [
    "# Data structure :'Word POS_tag syntactic_chunk_tag named_entity_tag \\n'\n",
    "\n",
    "# train = open(r'C:\\Users\\gabgu\\MSA\\PFE\\Perceptron\\master\\Dataset\\eng.train', 'at')\n",
    "# testa = open(r'C:\\Users\\gabgu\\MSA\\PFE\\Perceptron\\master\\Dataset\\eng.testa')\n",
    "# testb = open(r'C:\\Users\\gabgu\\MSA\\PFE\\Perceptron\\master\\Dataset\\eng.testb')\n",
    "  \n",
    "def get_words(path, pos): # Add a 'r' before the path for raw string, pos between 0 and 3 see data structure\n",
    "    data = open(path)\n",
    "    list_words = []\n",
    "    new_data = data.readlines()[2:] # Skip first 2 lines\n",
    "    mylist = list(new_data) # Make the data readable\n",
    "    for i in range(500): # TODO : CHANGES 20 TO len(mylist)\n",
    "        if splitter(mylist[i], ' ', pos): # it return None if the line est empty\n",
    "            list_words.append((splitter(mylist[i], ' ', pos)))\n",
    "#     print(list_words)\n",
    "    return list_words\n",
    "\n",
    "def splitter(line, separator, pos): # pos between 0 and 3 for CONLL2003\n",
    "    if line.isspace(): # Removing blank lines\n",
    "        return\n",
    "    new_sentence = []\n",
    "    for word in line.split(separator):\n",
    "        new_sentence.append(word)\n",
    "    return new_sentence[pos]\n",
    "\n",
    "def get_dictionary(list_of_words): # Return a dict with how many times a word appears\n",
    "    dicti = {}\n",
    "    for word in list_of_words:\n",
    "        if word in dicti:\n",
    "            dicti[word] = dicti[word] + 1\n",
    "        else:\n",
    "            dicti[word] = 1\n",
    "    return dicti\n",
    "\n",
    "def get_reduced_dictionary(dicti, limit): # return a dict with key >= limit\n",
    "    for v, k in list(dicti.items()):\n",
    "        if k <= limit:\n",
    "            del dicti[v]\n",
    "    return dicti\n",
    "\n",
    "def get_prefixe(reduced_dict, length_prefixe):\n",
    "    #TODO : remove all ponctuations signs\n",
    "    list_prefixes = []\n",
    "    for word in reduced_dict:\n",
    "        prefixe = word[:length_prefixe]\n",
    "        list_prefixes.append(prefixe)\n",
    "    print('ha', list_prefixes)\n",
    "    return list_prefixes\n",
    "\n",
    "def get_suffixe(reduced_dict, length_suffixe):\n",
    "    #TODO : remove all ponctuations signs\n",
    "    list_suffixes = []\n",
    "    for word in reduced_dict:\n",
    "        util_position = length_suffixe * (-1)\n",
    "        suffixe = word[util_position:]\n",
    "        list_suffixes.append(suffixe)\n",
    "    print('ho', list_suffixes)\n",
    "    return list_suffixes\n",
    "\n",
    "def get_capital(list_words):\n",
    "    # This function returns 2 lists : 1/ If the word have a capital and 2/ If the word is the 1st word of the sentence\n",
    "    list_capitals = []\n",
    "    list_first_word = []\n",
    "    flag_new_sentence = True\n",
    "    for word in list_words:\n",
    "        letter = word[0]\n",
    "        if letter.isupper():\n",
    "            list_capitals.append(1)\n",
    "            if flag_new_sentence:\n",
    "                list_first_word.append(1)\n",
    "                flag_ne\n",
    "                w_sentence = False\n",
    "        else:\n",
    "            list_capitals.append(0)\n",
    "        if word == '.': # OU '\\n' selon si on les enleve ou pas\n",
    "            flag_new_sentence = True\n",
    "    return (list_capitals, list_first_word)\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    list_of_words = get_words(r'C:\\Users\\gabgu\\MSA\\PFE\\Perceptron\\master\\Dataset\\eng.train', 0)\n",
    "    print(list_of_words)\n",
    "    dicti = get_dictionary(list_of_words)\n",
    "    reduced_dict = get_reduced_dictionary(dicti, 5)\n",
    "    list_prefixe_2 = get_prefixe(reduced_dict, 2)\n",
    "    list_prefixe_3 = get_prefixe(reduced_dict, 3)\n",
    "    list_suffixe_2 = get_suffixe(reduced_dict, 2)\n",
    "    list_suffixe_3 = get_suffixe(reduced_dict, 3)\n",
    "\n",
    "#TODO REMOVE ALL DOCSTART LINES    \n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "mot = '2'\n",
    "print(mot.isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "bojour\n",
      "popo\n",
      "{'date': 1999, 'bojour': 3, 'popo': 15}\n"
     ]
    }
   ],
   "source": [
    "test={\n",
    "    \"date\": 1999,\n",
    "    \"bojour\": 3, \n",
    "    \"popo\": 15\n",
    "}\n",
    "for x in test:\n",
    "    print(x)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
