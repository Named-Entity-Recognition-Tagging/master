{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten, \n",
    "    Conv2D,\n",
    "    MaxPooling2D)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0. 0. 0. ... 0. 0. 0.] (2352,)\n"
     ]
    }
   ],
   "source": [
    "# Data structure :'Word POS_tag syntactic_chunk_tag named_entity_tag \\n'\n",
    "# Order a word = prefixe 2, 3, 4, 5 then suffixe 2, 3, 4, 5, capitals, new_sentence, numbers, middle_dashes, appostrophies\n",
    "\n",
    "# train = open(r'C:\\Users\\gabgu\\MSA\\PFE\\Perceptron\\master\\Dataset\\eng.train', 'at')\n",
    "# testa = open(r'C:\\Users\\gabgu\\MSA\\PFE\\Perceptron\\master\\Dataset\\eng.testa')\n",
    "# testb = open(r'C:\\Users\\gabgu\\MSA\\PFE\\Perceptron\\master\\Dataset\\eng.testb')\n",
    "  \n",
    "def get_words(path, pos): # Add a 'r' before the path for raw string, pos between 0 and 3 see data structure\n",
    "    data = open(path)\n",
    "    list_words = []\n",
    "    new_data = data.readlines()[2:] # Skip first 2 lines\n",
    "    mylist = list(new_data) # Make the data readable\n",
    "    for i in range(500): # TODO : CHANGES 20 TO len(mylist)\n",
    "        if splitter(mylist[i], ' ', pos): # it return None if the line est empty\n",
    "            list_words.append((splitter(mylist[i], ' ', pos)))\n",
    "    return list_words\n",
    "\n",
    "def splitter(line, separator, pos): # pos between 0 and 3 for CONLL2003\n",
    "    if line.isspace(): # Removing blank lines\n",
    "        return\n",
    "    new_sentence = []\n",
    "    for word in line.split(separator):\n",
    "        new_sentence.append(word)\n",
    "    return new_sentence[pos]\n",
    "\n",
    "def get_dictionary(list_of_words): # Return a dict with how many times a word appears\n",
    "    dicti = {}\n",
    "    for word in list_of_words:\n",
    "        if word in dicti:\n",
    "            dicti[word] = dicti[word] + 1\n",
    "        else:\n",
    "            dicti[word] = 1\n",
    "    return dicti\n",
    "\n",
    "def get_reduced_dictionary(dicti, limit): # return a dict with key >= limit\n",
    "    for v, k in list(dicti.items()):\n",
    "        if k <= limit: # We don't want to take into account words that doesn't appear enough (limit)\n",
    "            del dicti[v]\n",
    "    return dicti\n",
    "\n",
    "def get_prefixe(reduced_dict, prefixe_length):\n",
    "    #TODO : remove all ponctuations signs\n",
    "    list_prefixes = []\n",
    "    for word in reduced_dict:\n",
    "        prefixe = word[:prefixe_length]\n",
    "        list_prefixes.append(prefixe)\n",
    "#     print('list prefixes', list_prefixes)\n",
    "    return list_prefixes\n",
    "\n",
    "def get_suffixe(reduced_dict, suffixe_length):\n",
    "    #TODO : remove all ponctuations signs\n",
    "    list_suffixes = []\n",
    "    for word in reduced_dict:\n",
    "        util_position = suffixe_length * (-1)\n",
    "        suffixe = word[util_position:]\n",
    "        list_suffixes.append(suffixe)\n",
    "#     print('list suffixes', list_suffixes)\n",
    "    return list_suffixes\n",
    "\n",
    "def has_capital(string):\n",
    "    if any(char.isupper() for char in string):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_capital(list_words):\n",
    "    # This function returns 2 lists:\n",
    "    list_capitals = []   # 1/ If the word have a capital\n",
    "    list_first_word = [] # 2/ If the word is the 1st word of the sentence\n",
    "    chara_end_sentence = ['.', '!', '?', '...'] # TODO : Check for '...' if it should be in this list\n",
    "    flag_new_sentence = True\n",
    "    for word in list_words:\n",
    "        letter = word[0] # First 'letter' of the word; can be number or special chara\n",
    "        if letter.isupper():\n",
    "            list_capitals.append(1)\n",
    "            if flag_new_sentence:\n",
    "                list_first_word.append(1)\n",
    "            else:\n",
    "                list_first_word.append(0)\n",
    "        else:\n",
    "            list_capitals.append(0)\n",
    "            list_first_word.append(0)\n",
    "        if letter in chara_end_sentence:\n",
    "            flag_new_sentence = True\n",
    "            continue\n",
    "        flag_new_sentence = False\n",
    "#     print(list_capitals, list_first_word)\n",
    "    return (list_capitals, list_first_word)\n",
    "\n",
    "\n",
    "def has_numbers(string):\n",
    "    if any(char.isdigit() for char in string):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_number(list_words): # Return array if there is a number in the word\n",
    "    list_numbers = []\n",
    "    for word in list_words:\n",
    "        if has_numbers(word):\n",
    "            list_numbers.append(1)\n",
    "        else:\n",
    "            list_numbers.append(0)\n",
    "#     print(list_numbers)\n",
    "    return list_numbers\n",
    "\n",
    "def has_middle_dash(string):\n",
    "    if any(char == '-' for char in string):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def get_middle_dash(list_words):\n",
    "    list_middle_dashes = []\n",
    "    for word in list_words:\n",
    "        if has_middle_dash(word):\n",
    "            list_middle_dashes.append(1)\n",
    "        else:\n",
    "            list_middle_dashes.append(0)\n",
    "#     print(list_middle_dashes)\n",
    "    return list_middle_dashes\n",
    "\n",
    "\n",
    "def has_appostrophy(string):\n",
    "    if any(char == '\\'' for char in string):\n",
    "        return 1\n",
    "    return 0\n",
    "    \n",
    "def get_appostrophy(list_words):\n",
    "    list_appostrophy = []\n",
    "    for word in list_words:\n",
    "        if has_appostrophy(word):\n",
    "            list_appostrophy.append(1)\n",
    "        else:\n",
    "            list_appostrophy.append(0)\n",
    "#     print(list_appostrophy)\n",
    "    return list_appostrophy\n",
    "\n",
    "\n",
    "\n",
    "def get_features():\n",
    "    list_of_words = get_words(r'C:\\Users\\gabgu\\MSA\\PFE\\Perceptron\\master\\Dataset\\eng.train', 0)\n",
    "#     print(list_of_words)\n",
    "    dicti = get_dictionary(list_of_words)\n",
    "    reduced_dict = get_reduced_dictionary(dicti, 5)\n",
    "    list_prefixe_2 = get_prefixe(reduced_dict, 2)\n",
    "    list_prefixe_3 = get_prefixe(reduced_dict, 3)\n",
    "    list_prefixe_4 = get_prefixe(reduced_dict, 4)\n",
    "    list_prefixe_5 = get_prefixe(reduced_dict, 5)\n",
    "    list_suffixe_2 = get_suffixe(reduced_dict, 2)\n",
    "    list_suffixe_3 = get_suffixe(reduced_dict, 3)\n",
    "    list_suffixe_4 = get_suffixe(reduced_dict, 4)\n",
    "    list_suffixe_5 = get_suffixe(reduced_dict, 5)\n",
    "    list_capitals, list_new_sentence = get_capital(list_of_words)\n",
    "    list_numbers = get_number(list_of_words)\n",
    "    list_middle_dashes = get_middle_dash(list_of_words)\n",
    "    list_appostrophies = get_appostrophy(list_of_words)\n",
    "    \n",
    "    get_array_for_sentence('Je suis un homme de 23 ans .', list_prefixe_2, list_prefixe_3, list_prefixe_4, list_prefixe_5,\n",
    "                           list_suffixe_2, list_suffixe_3, list_suffixe_4, list_suffixe_5)\n",
    "\n",
    "#TODO REMOVE ALL DOCSTART LINES    \n",
    "    \n",
    "\n",
    "\n",
    "# Now we need to create a vector to describe the words\n",
    "\n",
    "def get_vector_for_prefixe(word, prefixe_length, list_prefixe):\n",
    "    vector_prefixe = [] # It should be of size get_prefixe()\n",
    "    prefixe = word[:prefixe_length]\n",
    "    for pref in list_prefixe:\n",
    "        if pref == prefixe:\n",
    "            vector_prefixe.append(1)\n",
    "        else:\n",
    "            vector_prefixe.append(0)\n",
    "#     print('vector prefixe', vector_prefixe)\n",
    "    return vector_prefixe\n",
    "\n",
    "\n",
    "def get_vector_for_suffixe(word, suffixe_length, list_suffixe):\n",
    "    vector_suffixe = []\n",
    "    util_position = suffixe_length * (-1)\n",
    "    suffixe = word[util_position:]\n",
    "    for suf in list_suffixe:\n",
    "        if suf == suffixe:\n",
    "            vector_suffixe.append(1)\n",
    "        else:\n",
    "            vector_suffixe.append(0)\n",
    "#     print('vector suffixe', vector_suffixe)\n",
    "    return vector_suffixe\n",
    "\n",
    "def get_array_for_sentence(sentence, list_prefixe_2, list_prefixe_3, list_prefixe_4, list_prefixe_5,\n",
    "                          list_suffixe_2, list_suffixe_3, list_suffixe_4, list_suffixe_5, \n",
    "#                           list_capitals, list_new_sentence, list_numbers, list_middle_dashes, list_appostrophies\n",
    "                          ):\n",
    "    output = np.array([[]])\n",
    "    word_description = []\n",
    "    for word in sentence:\n",
    "#         word_description.append(get_vector_for_prefixe(word, 2, list_prefixe_2))\n",
    "#         word_description.append(get_vector_for_prefixe(word, 3, list_prefixe_3))\n",
    "#         word_description.append(get_vector_for_prefixe(word, 4, list_prefixe_4))\n",
    "#         word_description.append(get_vector_for_prefixe(word, 5, list_prefixe_5))\n",
    "#         word_description.append(get_vector_for_suffixe(word, 2, list_suffixe_2))\n",
    "#         word_description.append(get_vector_for_suffixe(word, 3, list_suffixe_3))\n",
    "#         word_description.append(get_vector_for_suffixe(word, 4, list_suffixe_4))\n",
    "#         word_description.append(get_vector_for_suffixe(word, 5, list_suffixe_5))\n",
    "#         word_description.append(has_capital(word))\n",
    "#         word_description.append(has_numbers(word))\n",
    "#         word_description.append(has_middle_dash(word))\n",
    "#         word_description.append(has_appostrophy(word))\n",
    "\n",
    "        word_description = get_vector_for_prefixe(word, 2, list_prefixe_2)\n",
    "        word_description = word_description + get_vector_for_prefixe(word, 3, list_prefixe_3)\n",
    "        word_description = word_description + get_vector_for_prefixe(word, 4, list_prefixe_4)\n",
    "        word_description = word_description + get_vector_for_prefixe(word, 5, list_prefixe_5)\n",
    "        word_description = word_description + get_vector_for_suffixe(word, 2, list_suffixe_2)\n",
    "        word_description = word_description + get_vector_for_suffixe(word, 3, list_suffixe_3)\n",
    "        word_description = word_description + get_vector_for_suffixe(word, 4, list_suffixe_4)\n",
    "        word_description = word_description + get_vector_for_suffixe(word, 5, list_suffixe_5)\n",
    "        word_description = word_description + [has_capital(word)]\n",
    "        word_description = word_description + [has_numbers(word)]\n",
    "        word_description = word_description + [has_middle_dash(word)]\n",
    "        word_description = word_description + [has_appostrophy(word)]\n",
    "        print('word', word_description)\n",
    "        output = np.append(output, np.array([word_description])) #this create a big array\n",
    "    print(output, output.shape)\n",
    "    return output\n",
    "        \n",
    "\n",
    "\n",
    "get_features()\n",
    "\n",
    "\n",
    "#     TODO : CONCATENATE THE LIST VECTOR TO HAVE THE FINAL DESCRIPTION IN A WORD IN 1 LIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "bojour\n",
      "popo\n",
      "{'date': 1999, 'bojour': 3, 'popo': 15}\n"
     ]
    }
   ],
   "source": [
    "test={\n",
    "    \"date\": 1999,\n",
    "    \"bojour\": 3, \n",
    "    \"popo\": 15\n",
    "}\n",
    "for x in test:\n",
    "    print(x)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-75d3543e822e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl_env\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   4698\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4699\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4700\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "line = np.array([[0, 0], [0, 0]])\n",
    "np.append(line, [3, 2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
